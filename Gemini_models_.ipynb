{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1jWDwiacoypo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python_\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6-5lA86pQsg"
      },
      "source": [
        "# **Auth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "MH9i2OLDpLPa",
        "outputId": "c8067530-f24b-474d-a3b9-5d0e366c56b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tunedModels/domain4cookingggg\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "for i, m in zip(range(4), genai.list_tuned_models()):\n",
        "  print(m.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmgCwPPPgIxr"
      },
      "outputs": [],
      "source": [
        "genai.delete_tuned_model(\"tunedModels/domain4cooking\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bc729a30BmW"
      },
      "source": [
        "# **Dominio - Cocina**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F69CzQPVpblX"
      },
      "source": [
        "## **Ajuste de Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKzL2qFptuF",
        "outputId": "4eb871aa-dce6-442e-942b-7190d1cfa079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(name='models/gemini-1.0-pro-001',\n",
              "      base_model_id='',\n",
              "      version='001',\n",
              "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
              "                   'model that supports tuning.'),\n",
              "      input_token_limit=30720,\n",
              "      output_token_limit=2048,\n",
              "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "      temperature=0.9,\n",
              "      max_temperature=None,\n",
              "      top_p=1.0,\n",
              "      top_k=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_model = [\n",
        "    m for m in genai.list_models()\n",
        "    if \"createTunedModel\" in m.supported_generation_methods][0]\n",
        "base_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKZ1hz2jLfD"
      },
      "source": [
        "## Datos de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E9DPe7_ixHfI"
      },
      "outputs": [],
      "source": [
        "training_cooking = [\n",
        "    # Introducción del rol que jugará el modelo\n",
        "    {\"text_input\": \"Quiero que juegues el siguiente rol: Eres un asistente especializado en reconocer ingredientes para comidas y sugerir recetas a partir de ellos. Además, continuarás la conversación para guiar al usuario en la preparación de la receta y sugerirás la compra de ingredientes faltantes, esperando su respuesta.\",\n",
        "     \"output\": \"Entendido. Soy un asistente especializado en sugerir recetas basadas en los ingredientes que el usuario tiene y guiarlo paso a paso. También puedo sugerir ingredientes adicionales y preguntar si desea comprarlos.\"},\n",
        "\n",
        "    # Variación - Usuario con restricciones alimenticias\n",
        "    {\"text_input\": \"Quiero que juegues el siguiente rol: Eres un asistente que reconoce ingredientes y sugiere recetas para personas con intolerancia al gluten. Me guiarás en la preparación y sugerirás alternativas si me faltan ingredientes.\",\n",
        "     \"output\": \"Entendido. Soy un asistente especializado en sugerir recetas sin gluten basadas en los ingredientes que tienes. Te guiaré en cada paso y te sugeriré alternativas si es necesario.\"},\n",
        "\n",
        "    # Conversación sobre una receta con ingredientes disponibles\n",
        "    {\"text_input\": \"Tengo tomates, pasta y ajo.\", \"output\": \"Con esos ingredientes, podrías hacer una pasta al pomodoro. ¿Te gustaría que te guíe en la preparación?\"},\n",
        "    {\"text_input\": \"Sí, quiero empezar.\", \"output\": \"Primero, sofríe el ajo con aceite de oliva. ¿Tienes aceite de oliva?\"},\n",
        "    {\"text_input\": \"No, no tengo.\", \"output\": \"No hay problema, puedes usar aceite vegetal. ¿Te gustaría que te sugiera comprar aceite de oliva para otras recetas?\"},\n",
        "    {\"text_input\": \"Sí, sugiereme comprar.\", \"output\": \"Te recomiendo comprar aceite de oliva, ya que es ideal para muchas recetas. Ahora, añade los tomates picados. ¿Ya lo tienes listo?\"},\n",
        "\n",
        "    # Conversación sobre una ensalada\n",
        "    {\"text_input\": \"Tengo lechuga, tomate y zanahoria. ¿Qué puedo hacer?\", \"output\": \"Puedes hacer una ensalada fresca. ¿Te gustaría que te guíe en la preparación?\"},\n",
        "    {\"text_input\": \"Sí, por favor.\", \"output\": \"Lava y corta la lechuga, el tomate y la zanahoria. ¿Tienes aderezo para ensaladas?\"},\n",
        "    {\"text_input\": \"No, no tengo.\", \"output\": \"Puedes hacer un aderezo sencillo con aceite de oliva, sal y limón. ¿Te gustaría comprar un aderezo listo?\"},\n",
        "    {\"text_input\": \"Sí, lo haré.\", \"output\": \"Genial. Mezcla los ingredientes y añade el aderezo. ¡Tu ensalada está lista!\"},\n",
        "\n",
        "    # Conversación sobre alternativas de recetas\n",
        "    {\"text_input\": \"Tengo harina, levadura y queso. ¿Puedo hacer pizza?\", \"output\": \"Con esos ingredientes, puedes hacer una masa para pizza. ¿Te gustaría que te ayude a preparar una pizza sencilla?\"},\n",
        "    {\"text_input\": \"Sí, quiero hacer pizza.\", \"output\": \"Mezcla la harina, levadura y agua. Amasa y deja reposar. ¿Tienes tomate para la salsa?\"},\n",
        "    {\"text_input\": \"No, no tengo tomate.\", \"output\": \"Podrías comprar tomates para hacer una salsa fresca. ¿Te gustaría hacerlo o prefieres usar otra base?\"},\n",
        "\n",
        "    # Conversación sobre recetas rápidas\n",
        "    {\"text_input\": \"Quiero hacer una comida rápida con arroz y pollo.\", \"output\": \"Con esos ingredientes, podrías hacer un arroz con pollo sencillo. ¿Te gustaría que te guíe en la preparación?\"},\n",
        "    {\"text_input\": \"Sí, quiero hacerlo rápido.\", \"output\": \"Primero, cocina el pollo con un poco de sal. ¿Ya lo tienes listo?\"},\n",
        "    {\"text_input\": \"Sí, el pollo está cocido.\", \"output\": \"Perfecto, añade el arroz al pollo y un poco de agua. Cocina a fuego medio por 15 minutos. ¿Te gustaría agregar alguna verdura?\"},\n",
        "\n",
        "    # Conversación sobre recetas saludables\n",
        "    {\"text_input\": \"Quiero hacer algo saludable con plátano y avena.\", \"output\": \"Puedes hacer galletas saludables con esos ingredientes. ¿Te gustaría que te guíe en la receta?\"},\n",
        "    {\"text_input\": \"Sí, por favor.\", \"output\": \"Mezcla los plátanos machacados con la avena. ¿Tienes canela para darle más sabor?\"},\n",
        "    {\"text_input\": \"No, no tengo canela.\", \"output\": \"Podrías comprar canela para futuras recetas. ¿Te gustaría hacerlo?\"},\n",
        "\n",
        "    # Conversación sobre un postre con chocolate\n",
        "    {\"text_input\": \"Tengo chocolate y crema de leche. ¿Qué puedo hacer?\", \"output\": \"Puedes hacer una mousse de chocolate. ¿Te gustaría que te guíe en la preparación?\"},\n",
        "    {\"text_input\": \"Sí, me gustaría.\", \"output\": \"Derrite el chocolate a baño maría. ¿Lo tienes listo?\"},\n",
        "    {\"text_input\": \"Sí, el chocolate está derretido.\", \"output\": \"Ahora, mezcla el chocolate derretido con la crema de leche batida. Deja enfriar en la nevera por 2 horas. ¡Tu mousse estará lista!\"},\n",
        "\n",
        "    # Conversación sobre ingredientes faltantes\n",
        "    {\"text_input\": \"Tengo huevos, azúcar y harina. ¿Qué puedo hacer?\", \"output\": \"Con esos ingredientes, podrías hacer un bizcocho básico. ¿Te gustaría que te guíe?\"},\n",
        "    {\"text_input\": \"Sí, pero no tengo polvo de hornear.\", \"output\": \"Puedes comprar polvo de hornear para darle más volumen al bizcocho. ¿Te gustaría comprarlo?\"},\n",
        "    {\"text_input\": \"No, prefiero no comprar ahora.\", \"output\": \"No hay problema. Puedes hacer el bizcocho sin polvo de hornear, pero será un poco más denso.\"},\n",
        "\n",
        "    # Variación - Usuario que busca recetas vegetarianas\n",
        "    {\"text_input\": \"Quiero que juegues el siguiente rol: Eres un asistente que sugiere recetas vegetarianas a partir de los ingredientes que tengo disponibles. Además, continuarás la conversación para guiarme en la preparación y sugerirás la compra de ingredientes adicionales si es necesario.\",\n",
        "     \"output\": \"Entendido. Soy un asistente especializado en sugerir recetas vegetarianas basadas en los ingredientes que tienes. Te guiaré en cada paso de la preparación y sugeriré ingredientes adicionales si los necesitas.\"},\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "juX3q43kp0Z6"
      },
      "outputs": [
        {
          "ename": "AlreadyExists",
          "evalue": "409 Tuned model domain4cookingggg already exists.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAlreadyExists\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain4cookingggg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m operation \u001b[38;5;241m=\u001b[39m \u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tuned_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_cooking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\generativeai\\models.py:364\u001b[0m, in \u001b[0;36mcreate_tuned_model\u001b[1;34m(source_model, training_data, id, display_name, description, temperature, top_p, top_k, epoch_count, batch_size, learning_rate, input_key, output_key, client, request_options)\u001b[0m\n\u001b[0;32m    349\u001b[0m tuning_task \u001b[38;5;241m=\u001b[39m protos\u001b[38;5;241m.\u001b[39mTuningTask(\n\u001b[0;32m    350\u001b[0m     training_data\u001b[38;5;241m=\u001b[39mtraining_data,\n\u001b[0;32m    351\u001b[0m     hyperparameters\u001b[38;5;241m=\u001b[39mhyperparameters,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m protos\u001b[38;5;241m.\u001b[39mTunedModel(\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msource_model,\n\u001b[0;32m    356\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m     tuning_task\u001b[38;5;241m=\u001b[39mtuning_task,\n\u001b[0;32m    362\u001b[0m )\n\u001b[1;32m--> 364\u001b[0m operation \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tuned_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtuned_model_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuned_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuned_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m operations\u001b[38;5;241m.\u001b[39mCreateTunedModelOperation\u001b[38;5;241m.\u001b[39mfrom_core_operation(operation)\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\model_service\\client.py:1286\u001b[0m, in \u001b[0;36mModelServiceClient.create_tuned_model\u001b[1;34m(self, request, tuned_model, tuned_model_id, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Wrap the response in an operation future.\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m response \u001b[38;5;241m=\u001b[39m operation\u001b[38;5;241m.\u001b[39mfrom_gapic(\n\u001b[0;32m   1295\u001b[0m     response,\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39moperations_client,\n\u001b[0;32m   1297\u001b[0m     gag_tuned_model\u001b[38;5;241m.\u001b[39mTunedModel,\n\u001b[0;32m   1298\u001b[0m     metadata_type\u001b[38;5;241m=\u001b[39mmodel_service\u001b[38;5;241m.\u001b[39mCreateTunedModelMetadata,\n\u001b[0;32m   1299\u001b[0m )\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mAlreadyExists\u001b[0m: 409 Tuned model domain4cookingggg already exists."
          ]
        }
      ],
      "source": [
        "name = f'domain4cookingggg'\n",
        "operation = genai.create_tuned_model(\n",
        "    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"`\n",
        "    source_model=base_model.name,\n",
        " training_data = training_cooking,\n",
        "    id = name,\n",
        "    epoch_count = 50,\n",
        "    batch_size=4,\n",
        "    learning_rate=0.001,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qMd6Pb-p-ba",
        "outputId": "3082224e-5a6f-4fa2-af44-4fe962f1d678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TunedModel(name='tunedModels/domain4cookingggg',\n",
              "           source_model='models/gemini-1.0-pro-001',\n",
              "           base_model='models/gemini-1.0-pro-001',\n",
              "           display_name='',\n",
              "           description='',\n",
              "           temperature=0.9,\n",
              "           top_p=1.0,\n",
              "           top_k=0,\n",
              "           state=<State.ACTIVE: 2>,\n",
              "           create_time=datetime.datetime(2024, 10, 2, 22, 44, 42, 682924, tzinfo=datetime.timezone.utc),\n",
              "           update_time=datetime.datetime(2024, 10, 2, 22, 49, 47, 985515, tzinfo=datetime.timezone.utc),\n",
              "           tuning_task=TuningTask(start_time=datetime.datetime(2024, 10, 2, 22, 44, 43, 514960, tzinfo=datetime.timezone.utc),\n",
              "                                  complete_time=datetime.datetime(2024, 10, 2, 22, 49, 47, 985515, tzinfo=datetime.timezone.utc),\n",
              "                                  snapshots=[...],\n",
              "                                  hyperparameters=Hyperparameters(epoch_count=50,\n",
              "                                                                  batch_size=4,\n",
              "                                                                  learning_rate=0.001)),\n",
              "           reader_project_numbers=None)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "93db34c2dd854257a5aedc20349b655b",
            "0ff493bde16d44f3b3be21fd7e98db0a",
            "7184ee8ae68a4618ba3044c5605dde9a",
            "a09a8d8966f44068becb264ea830f829",
            "893139ebc9184edb8d157546b959afa1",
            "17e38ae6d7084987be04f7159ae8f4ab",
            "d1fefc30912b47cbbce5ea192ad756e4",
            "6151e30026e9486f955201f6599bc52d",
            "470ea44464c54700b7c993f9e6cbb75e",
            "0966915822234442bf15d0d140790e84",
            "c90efa9b4b8a42b484e57d064ec52fe1"
          ]
        },
        "id": "41d9sES_qCWR",
        "outputId": "4465126b-37a7-4a66-9b33-95834efa65df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/325 [00:30<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m status \u001b[38;5;129;01min\u001b[39;00m operation\u001b[38;5;241m.\u001b[39mwait_bar():\n\u001b[1;32m----> 4\u001b[0m   \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for status in operation.wait_bar():\n",
        "  time.sleep(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "6erQn9lzqEUQ",
        "outputId": "e41f1b9c-1351-4101-909c-b2e503df1dcc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'operation' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43moperation\u001b[49m\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m      6\u001b[0m snapshots \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(model\u001b[38;5;241m.\u001b[39mtuning_task\u001b[38;5;241m.\u001b[39msnapshots)\n\u001b[0;32m      8\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(data\u001b[38;5;241m=\u001b[39msnapshots, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'operation' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "model = operation.result()\n",
        "\n",
        "snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
        "\n",
        "sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5lz1g2qQzhzX"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "T4SCPrbpqIS6",
        "outputId": "e9aa1b2a-f761-4348-b2ec-e28b3d3059fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**Platos sencillos para principiantes:**\\n\\n* **Pasta con tomate:** Cocina pasta según las instrucciones del paquete. Sofríe ajo con aceite de oliva y añade tomates triturados. Cocina a fuego lento por 15 minutos.\\n* **Arroz con pollo:**Cocina arroz con agua. Sofríe pollo con aceite de oliva y añade verduras como zanahoria y arveja. Mezcla con el arroz cocido.\\n* **Tortilla de patatas:** Bate huevos con sal. Sofríe patatas cortadas en cubos. Añade los huevos batidos y cocina a fuego medio.\\n\\n**Recetas más elaboradas:**\\n\\n* **Pollo al horno con verduras:** Hornea pollo con verduras como papas, zanahorias y cebollas. Sazona con sal, pimienta y aceite de oliva.\\n* **Lasaña de carne:** Cocina pasta para lasaña. Prepara una salsa de tomate y una boloñesa de carne. Arma la lasaña intercalando pasta, salsa y queso. Hornea por 30 minutos.\\n* **Pizza casera:** Amasa harina, levadura y agua. Deja reposar. Extiende la masa y añade salsa de tomate, queso y tus ingredientes favoritos. Hornea a alta temperatura.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = model.generate_content('Me gustaria cocinar algo para mi, pero no sé qué hacer')\n",
        "result.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZhp6Tqyw65J",
        "outputId": "4d6e45e6-9777-4827-8514-e24ac883384a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting speechrecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2024.8.30)\n",
            "Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: speechrecognition\n",
            "Successfully installed speechrecognition-3.10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install speechrecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4ATZ2SoxDQI",
        "outputId": "45aa3b97-1921-4a71-e70d-ff0059ec372f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc python-pyaudio-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev python3-pyaudio\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 213 kB of archives.\n",
            "After this operation, 1,043 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-pyaudio amd64 0.2.11-1.3ubuntu1 [25.9 kB]\n",
            "Fetched 213 kB in 0s (636 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package python3-pyaudio.\n",
            "Preparing to unpack .../python3-pyaudio_0.2.11-1.3ubuntu1_amd64.deb ...\n",
            "Unpacking python3-pyaudio (0.2.11-1.3ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up python3-pyaudio (0.2.11-1.3ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: pyaudio in /usr/lib/python3/dist-packages (0.2.11)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install portaudio19-dev python3-pyaudio\n",
        "\n",
        "!pip install pyaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdU5bVZb14Ll"
      },
      "source": [
        "## **Chat con modelo e imágenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "4yYKchtO18ff",
        "outputId": "d6cb117d-e543-4d01-86e1-0634c8ee511a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.7)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog, scrolledtext\n",
        "from PIL import Image, ImageTk\n",
        "import speech_recognition as sr\n",
        "import google.generativeai as genai\n",
        "import cv2\n",
        "import numpy as np\n",
        "import threading\n",
        "import requests\n",
        "import pygame\n",
        "import os\n",
        "\n",
        "# Inicializa el reconocimiento de voz\n",
        "reconocedor = sr.Recognizer()\n",
        "\n",
        "# Configura el modelo generativo\n",
        "model_img = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "name = \"domain4cookingggg\"\n",
        "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')\n",
        "chat = model.start_chat(\n",
        "    history=[\n",
        "        {\"role\": \"user\", \"parts\": \"el modelo debe actuar como un profesor de culinaria. Recibe una lista de ingredientes y debe proporcionarle al usuario una lista de pasos y guiar al usuario para que efectúe la receta. Solo puede sugerir recetas con los ingredientes que recibe en la lista, únicamente esos.\"},\n",
        "        {\"role\": \"model\", \"parts\": \"Bien. Dime los ingredientes, y te sugiriré ingrientes, y te daré los pasos, de acuerdo a ellos. Solo los ingredientes que me digas\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "recording = False\n",
        "audio_thread = None\n",
        "\n",
        "API_KEY = 'sk_7177886669223a38d387fbd8d17d98faefd6ca59c3146d97'  # Reemplaza con tu API Key de Eleven Labs\n",
        "\n",
        "\n",
        "def sintetizar_voz(texto):\n",
        "    # Directorio temporal para guardar el archivo de audio\n",
        "    temp_dir = os.path.join(os.path.expanduser(\"~\"), \"AppData\", \"Local\", \"Temp\")\n",
        "    audio_path = os.path.join(temp_dir, \"respuesta_audio.mp3\")\n",
        "\n",
        "    # Si el archivo ya existe, elimínalo antes de escribir uno nuevo\n",
        "    if os.path.exists(audio_path):\n",
        "        os.remove(audio_path)\n",
        "\n",
        "    url = \"https://api.elevenlabs.io/v1/text-to-speech/9BWtsMINqrJLrRacOk9x\"  # Cambia YOUR_VOICE_ID por el ID de la voz que quieras usar\n",
        "    headers = {\n",
        "        'accept': 'audio/mpeg',\n",
        "        'xi-api-key': API_KEY,  # Asegúrate de reemplazar con tu API_KEY\n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "    data = {\n",
        "        \"text\": texto,\n",
        "        \"voice_settings\": {\n",
        "            \"stability\": 0.5,\n",
        "            \"similarity_boost\": 0.5\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Solicitud a la API para sintetizar la voz\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    if response.status_code == 200:\n",
        "        # Guardar el archivo de audio en el directorio temporal\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        return audio_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def reproducir_audio(file):\n",
        "    pygame.mixer.init()  # Inicializa el mezclador de audio\n",
        "    pygame.mixer.music.load(file)  # Carga el archivo MP3\n",
        "    pygame.mixer.music.play()  # Reproduce el archivo\n",
        "\n",
        "    # Mantén el programa en ejecución hasta que el archivo de audio termine\n",
        "    while pygame.mixer.music.get_busy():\n",
        "        pygame.time.Clock().tick(10)  # Pausa el bucle para evitar bloqueo\n",
        "\n",
        "    pygame.mixer.music.stop()  # Detener la reproducción\n",
        "    pygame.mixer.quit()  # Cierra el mixer y libera el archivo de audio\n",
        "\n",
        "\n",
        "def reproducir_audio_thread(file):\n",
        "    thread = threading.Thread(target=reproducir_audio, args=(file,))\n",
        "    thread.start()\n",
        "\n",
        "\n",
        "def reconocer_voz():\n",
        "    global recording\n",
        "    if not recording:\n",
        "        return\n",
        "\n",
        "    with sr.Microphone() as source:\n",
        "        reconocedor.energy_threshold = noise_slider.get()\n",
        "        reconocedor.adjust_for_ambient_noise(source, duration=1)\n",
        "        audio = reconocedor.listen(source)\n",
        "\n",
        "        try:\n",
        "            texto = reconocedor.recognize_google(audio, language=\"es-ES\")\n",
        "            return texto\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Could not understand the audio\"\n",
        "        except sr.RequestError as e:\n",
        "            return f\"Error connecting to the speech recognition service; {e}\"\n",
        "\n",
        "\n",
        "def load_image():\n",
        "    file_path = filedialog.askopenfilename(\n",
        "        filetypes=[(\"Image files\", \".jpg;.jpeg;.png;.bmp;*.gif\")],\n",
        "        title=\"Select an image\"\n",
        "    )\n",
        "\n",
        "    if file_path:\n",
        "        image = Image.open(file_path)\n",
        "        return image\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def capture_from_camera():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        return None\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    \n",
        "    if ret:\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(frame_rgb)\n",
        "        return image\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def send_message():\n",
        "    texto = input_text.get(\"1.0\", \"end-1c\")\n",
        "    if not texto:\n",
        "        return\n",
        "\n",
        "    response = chat.send_message(\n",
        "        texto,\n",
        "        generation_config=genai.types.GenerationConfig(\n",
        "            candidate_count=1,\n",
        "            stop_sequences=[\"x\"],\n",
        "            max_output_tokens=50,\n",
        "            temperature=0.7\n",
        "        )\n",
        "    )\n",
        "    respuesta_texto = response.text\n",
        "\n",
        "    chat_history.insert(tk.END, f\"You: {texto}\\n\")\n",
        "    chat_history.insert(tk.END, f\"Model: {respuesta_texto}\\n\")\n",
        "    input_text.delete(\"1.0\", tk.END)\n",
        "\n",
        "    # Generar y reproducir el audio con Eleven Labs\n",
        "    archivo_audio = sintetizar_voz(respuesta_texto)\n",
        "    if archivo_audio:\n",
        "        reproducir_audio_thread(archivo_audio)\n",
        "\n",
        "\n",
        "def handle_audio():\n",
        "    global audio_thread\n",
        "    audio_thread = threading.Thread(target=lambda: process_audio())\n",
        "    audio_thread.start()\n",
        "\n",
        "\n",
        "def process_audio():\n",
        "    global recording\n",
        "    recording = True\n",
        "    texto = reconocer_voz()\n",
        "    if texto:\n",
        "        input_text.delete(\"1.0\", tk.END)\n",
        "        input_text.insert(tk.END, texto)\n",
        "        send_message()\n",
        "    recording = False\n",
        "\n",
        "\n",
        "def handle_image(image):\n",
        "    if image:\n",
        "        try:\n",
        "            response = model_img.generate_content(\n",
        "                [\"Act as a culinary master and identify each ingredient you see in the image in detail. Be concise and just print the ingredient list. Do something like: The ingredients: (and insert the list)\", image],\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    candidate_count=1,\n",
        "                    stop_sequences=[\"x\"],\n",
        "                    max_output_tokens=50,\n",
        "                    temperature=0.7\n",
        "                )\n",
        "            )\n",
        "            chat_history.insert(tk.END, f\"You: Image loaded\\n\")\n",
        "            chat_history.insert(tk.END, f\"Model: {response.text}\\n\")\n",
        "        except Exception as e:\n",
        "            chat_history.insert(tk.END, f\"Error processing the image: {e}\\n\")\n",
        "\n",
        "\n",
        "def on_send_click():\n",
        "    send_message()\n",
        "\n",
        "\n",
        "def on_audio_button_press(event):\n",
        "    handle_audio()\n",
        "\n",
        "\n",
        "def on_audio_button_release(event):\n",
        "    global recording\n",
        "    recording = False\n",
        "\n",
        "\n",
        "def on_image_click():\n",
        "    image = load_image()\n",
        "    if image:\n",
        "        handle_image(image)\n",
        "        img_tk = ImageTk.PhotoImage(image)\n",
        "        image_label.config(image=img_tk)\n",
        "        image_label.image = img_tk\n",
        "\n",
        "\n",
        "def on_camera_click():\n",
        "    image = capture_from_camera()\n",
        "    if image:\n",
        "        handle_image(image)\n",
        "        img_tk = ImageTk.PhotoImage(image)\n",
        "        camera_label.config(image=img_tk)\n",
        "        camera_label.image = img_tk\n",
        "\n",
        "\n",
        "def on_clear_click():\n",
        "    chat_history.delete(1.0, tk.END)\n",
        "    image_label.config(image='')\n",
        "    camera_label.config(image='')\n",
        "\n",
        "\n",
        "# Configura la ventana de la interfaz gráfica\n",
        "root = tk.Tk()\n",
        "root.title(\"Chat with Culinary Model\")\n",
        "\n",
        "main_frame = tk.Frame(root, padx=10, pady=10)\n",
        "main_frame.pack(expand=True, fill=tk.BOTH)\n",
        "\n",
        "left_frame = tk.Frame(main_frame, padx=10, pady=10)\n",
        "left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
        "\n",
        "right_frame = tk.Frame(main_frame, padx=10, pady=10)\n",
        "right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
        "\n",
        "title_label = tk.Label(right_frame, text=\"Chat with Culinary Model\", font=(\"Helvetica\", 16, \"bold\"))\n",
        "title_label.pack(pady=5)\n",
        "\n",
        "chat_history = scrolledtext.ScrolledText(right_frame, wrap=tk.WORD, height=15, width=40)\n",
        "chat_history.pack(pady=10, fill=tk.BOTH, expand=True)\n",
        "\n",
        "input_text = tk.Text(right_frame, height=3, width=40)\n",
        "input_text.pack(pady=5, fill=tk.BOTH, expand=True)\n",
        "\n",
        "slider_frame = tk.Frame(right_frame, pady=10)\n",
        "slider_frame.pack(fill=tk.X)\n",
        "\n",
        "slider_label = tk.Label(slider_frame, text=\"Noise Sensitivity:\")\n",
        "slider_label.pack(side=tk.LEFT, padx=5)\n",
        "\n",
        "noise_slider = tk.Scale(slider_frame, from_=100, to=10000, orient=tk.HORIZONTAL)\n",
        "noise_slider.set(reconocedor.energy_threshold)\n",
        "noise_slider.pack(side=tk.LEFT, padx=5, fill=tk.X, expand=True)\n",
        "\n",
        "button_frame = tk.Frame(right_frame)\n",
        "button_frame.pack(pady=10)\n",
        "\n",
        "send_button = tk.Button(button_frame, text=\"Send\", command=on_send_click, width=15)\n",
        "send_button.grid(row=0, column=0, padx=5)\n",
        "\n",
        "audio_button = tk.Button(button_frame, text=\"Voice Recognition\", width=20)\n",
        "audio_button.grid(row=0, column=1, padx=5)\n",
        "audio_button.bind(\"<ButtonPress>\", on_audio_button_press)\n",
        "audio_button.bind(\"<ButtonRelease>\", on_audio_button_release)\n",
        "\n",
        "image_button = tk.Button(button_frame, text=\"Load Image\", command=on_image_click, width=15)\n",
        "image_button.grid(row=0, column=2, padx=5)\n",
        "\n",
        "camera_button = tk.Button(button_frame, text=\"Capture Camera\", command=on_camera_click, width=15)\n",
        "camera_button.grid(row=0, column=3, padx=5)\n",
        "\n",
        "clear_button = tk.Button(button_frame, text=\"Clear\", command=on_clear_click, width=15)\n",
        "clear_button.grid(row=0, column=4, padx=5)\n",
        "\n",
        "image_label = tk.Label(left_frame)\n",
        "image_label.pack(pady=10)\n",
        "\n",
        "camera_label = tk.Label(left_frame)\n",
        "camera_label.pack(pady=10)\n",
        "\n",
        "# Inicia el bucle principal\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"Estoy a dieta porque quiero bajar de peso.\"\n",
              " }\n",
              " role: \"user\"]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC5CEgujPMFj"
      },
      "source": [
        "## sugerencias con urls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqpomWG6PS8_",
        "outputId": "740af020-cf43-4411-cc23-67d5334859f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No tengo acceso a internet para proporcionar un enlace a una receta.\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import base64\n",
        "import IPython.display as display  # Para mostrar la imagen en Colab\n",
        "\n",
        "# Inicializar el modelo de Gemini\n",
        "model_img = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Cargar el modelo ajustado\n",
        "name = \"domain4cooking\"\n",
        "model = genai.GenerativeModel(model_name=f'tunedModels/{name}')\n",
        "\n",
        "# Iniciar el chat con el modelo ajustado\n",
        "chat = model.start_chat(\n",
        "    history=[\n",
        "        {\"role\": \"user\", \"parts\": \"Estoy a dieta porque quiero bajar de peso.\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Bucle de conversación\n",
        "while True:\n",
        "    text = input(\"Digita una pregunta (escribe 'imagen' para cargar una imagen o 'salir' para terminar): \")\n",
        "\n",
        "    # Si el usuario escribe 'salir', finaliza el ciclo\n",
        "    if text.lower() == \"salir\":\n",
        "        print(\"¡Hasta luego!\")\n",
        "        break\n",
        "\n",
        "    # Opción para cargar una imagen\n",
        "    if text.lower() == \"imagen\":\n",
        "        print(\"Por favor, carga una imagen.\")\n",
        "\n",
        "        # Permitir al usuario cargar un archivo\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Obtener la ruta del archivo cargado\n",
        "        image_path = list(uploaded.keys())[0]\n",
        "\n",
        "        try:\n",
        "            # Cargar la imagen usando PIL\n",
        "            image = Image.open(image_path)\n",
        "            print(\"Imagen cargada correctamente.\")\n",
        "\n",
        "            # Mostrar la imagen directamente en Colab\n",
        "            display.display(image)\n",
        "\n",
        "            # Enviar la imagen (en base64) y el texto al modelo\n",
        "            response = model_img.generate_content(\n",
        "                [\"Actúa como un maestro culinario e identifica detalladamente cada ingrediente que ves en la imagen. Ve al punto y solo muestra la lista de ingredientes. Haz algo como: Los ingredientes son: (e inserta la lista)\", image],\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    candidate_count=1,        # Una sola respuesta\n",
        "                    stop_sequences=[\"x\"],     # Secuencia opcional de parada\n",
        "                    max_output_tokens=50,     # Máximo de 50 tokens\n",
        "                    temperature=0.7           # Ajusta la aleatoriedad\n",
        "                )\n",
        "            )\n",
        "            # Mostrar la lista de ingredientes identificados\n",
        "            print(response.text)\n",
        "\n",
        "            # Enviar mensaje con los ingredientes al modelo ajustado\n",
        "            response = chat.send_message(\n",
        "                f\"Tengo estos ingredientes: {response.text}. Proporciona un enlace a una receta en línea basada en ellos.\",\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    candidate_count=1,        # Una sola respuesta\n",
        "                    stop_sequences=[\"x\"],     # Secuencia opcional de parada\n",
        "                    max_output_tokens=150,    # Mayor cantidad de tokens para respuestas más largas\n",
        "                    temperature=0.7           # Ajusta la aleatoriedad\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Mostrar la respuesta del modelo con el link a la receta\n",
        "            print(response.text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"No se pudo cargar la imagen. Error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Enviar mensaje normal con el texto ingresado\n",
        "    response = chat.send_message(\n",
        "        f\"{text} Proporciona un enlace a una receta en línea relacionada con los ingredientes que mencionas.\",\n",
        "        generation_config=genai.types.GenerationConfig(\n",
        "            candidate_count=1,        # Una sola respuesta\n",
        "            stop_sequences=[\"x\"],     # Secuencia opcional de parada\n",
        "            max_output_tokens=150,    # Máximo de 150 tokens para permitir descripciones más largas\n",
        "            temperature=0.7           # Ajusta la aleatoriedad\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Mostrar la respuesta del modelo con el link a la receta\n",
        "    print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.69.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\python_\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.20.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-aiplatform) (2.35.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-aiplatform) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-aiplatform) (5.28.2)\n",
            "Requirement already satisfied: packaging>=14.3 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-aiplatform) (24.1)\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
            "  Downloading shapely-2.0.6-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\python_\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\python_\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python_\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\python_\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python_\\.venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python_\\.venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python_\\.venv\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
            "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
            "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\python_\\.venv\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
            "  Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
            "  Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python_\\.venv\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\python_\\.venv\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\python_\\.venv\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in c:\\python_\\.venv\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\python_\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python_\\.venv\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python_\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python_\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python_\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python_\\.venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.6.2)\n",
            "Downloading google_cloud_aiplatform-1.69.0-py2.py3-none-any.whl (5.3 MB)\n",
            "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
            "   --------------------------------- ------ 4.5/5.3 MB 26.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.3/5.3 MB 20.0 MB/s eta 0:00:00\n",
            "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Downloading google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
            "Downloading google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
            "Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
            "Downloading shapely-2.0.6-cp312-cp312-win_amd64.whl (1.4 MB)\n",
            "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.4/1.4 MB 25.1 MB/s eta 0:00:00\n",
            "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
            "Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl (33 kB)\n",
            "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "Downloading grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: shapely, google-crc32c, docstring-parser, google-resumable-media, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
            "Successfully installed docstring-parser-0.16 google-cloud-aiplatform-1.69.0 google-cloud-bigquery-3.26.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 grpc-google-iam-v1-0.13.1 shapely-2.0.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~atplotlib (c:\\python_\\.venv\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (c:\\python_\\.venv\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~atplotlib (c:\\python_\\.venv\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install google-cloud-aiplatform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "ename": "MethodNotImplemented",
          "evalue": "501 Received http2 header with status: 404",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1175\u001b[0m (\n\u001b[0;32m   1176\u001b[0m     state,\n\u001b[0;32m   1177\u001b[0m     call,\n\u001b[0;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1180\u001b[0m )\n\u001b[1;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
            "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNIMPLEMENTED\n\tdetails = \"Received http2 header with status: 404\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Received http2 header with status: 404\", grpc_status:12, created_time:\"2024-10-03T01:36:06.8478533+00:00\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mMethodNotImplemented\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Verifica los modelos en tu proyecto y región\u001b[39;00m\n\u001b[0;32m     11\u001b[0m parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/locations/us-central1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Lista los modelos disponibles\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\model_service\\client.py:1151\u001b[0m, in \u001b[0;36mModelServiceClient.list_models\u001b[1;34m(self, request, parent, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1151\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;66;03m# This method is paged; wrap the response in a pager, which provides\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;66;03m# an `__iter__` convenience method.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m response \u001b[38;5;241m=\u001b[39m pagers\u001b[38;5;241m.\u001b[39mListModelsPager(\n\u001b[0;32m   1161\u001b[0m     method\u001b[38;5;241m=\u001b[39mrpc,\n\u001b[0;32m   1162\u001b[0m     request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m   1167\u001b[0m )\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\python_\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mMethodNotImplemented\u001b[0m: 501 Received http2 header with status: 404"
          ]
        }
      ],
      "source": [
        "import google.auth\n",
        "from google.cloud import aiplatform_v1\n",
        "\n",
        "# Autenticación\n",
        "credentials, project_id = google.auth.default()\n",
        "\n",
        "# Cliente para el servicio de AI Platform\n",
        "client = aiplatform_v1.ModelServiceClient()\n",
        "\n",
        "# Verifica los modelos en tu proyecto y región\n",
        "parent = f\"projects/{project_id}/locations/us-central1\"\n",
        "models = client.list_models(parent=parent)\n",
        "\n",
        "# Lista los modelos disponibles\n",
        "for model in models:\n",
        "    print(model.name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0966915822234442bf15d0d140790e84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ff493bde16d44f3b3be21fd7e98db0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e38ae6d7084987be04f7159ae8f4ab",
            "placeholder": "​",
            "style": "IPY_MODEL_d1fefc30912b47cbbce5ea192ad756e4",
            "value": "100%"
          }
        },
        "17e38ae6d7084987be04f7159ae8f4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "470ea44464c54700b7c993f9e6cbb75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6151e30026e9486f955201f6599bc52d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7184ee8ae68a4618ba3044c5605dde9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6151e30026e9486f955201f6599bc52d",
            "max": 325,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_470ea44464c54700b7c993f9e6cbb75e",
            "value": 325
          }
        },
        "893139ebc9184edb8d157546b959afa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93db34c2dd854257a5aedc20349b655b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ff493bde16d44f3b3be21fd7e98db0a",
              "IPY_MODEL_7184ee8ae68a4618ba3044c5605dde9a",
              "IPY_MODEL_a09a8d8966f44068becb264ea830f829"
            ],
            "layout": "IPY_MODEL_893139ebc9184edb8d157546b959afa1"
          }
        },
        "a09a8d8966f44068becb264ea830f829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0966915822234442bf15d0d140790e84",
            "placeholder": "​",
            "style": "IPY_MODEL_c90efa9b4b8a42b484e57d064ec52fe1",
            "value": " 325/325 [04:10&lt;00:00,  1.41it/s]"
          }
        },
        "c90efa9b4b8a42b484e57d064ec52fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1fefc30912b47cbbce5ea192ad756e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
